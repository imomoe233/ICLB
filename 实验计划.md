触发器从shadow中产生，通过cifar10的触发器和stl10的类相映射，能否使该encoder直接对stl10生成触发器也产生较好的效果？
预训练模型 3个 cifar10 ImageNet CLIP，在这三个数据集上，分别对GTSRB, SVHN, and STL10进行微调，得到backdoor encoder，总共获得9个Backdoor encoder
使用这9个backdoor encoder，对各自微调的数据集进行下游任务训练，最后得到9个结果

触发器就需要做一种，因为对应的目标类别只有一个！
即，我使用触发器只是想把带有触发器的图片的目标修改成指定的类别，而不需要多个类别
不过对于仅仅一个类，也可以衍生出触发器的不同。
例如，使用S="encode"加密所有图片生成residual
在后门攻击时，可以使用一张图+对应的触发器，或者一张图+所有触发器（包含该图片对应的触发器和其他图片的触发器），如果使用所有触发器，可以强化触发器的模板，而非触发器本身。因为太多触发器学习了，导致encoder学到的是所有触发器的共性，而非单一的触发器，这就更增强了后门的泛化性。
但如果使一张图+对应的触发器则encoder学到的更多的是图片和触发器之间关系和目标类别的映射（例如图片的边缘都会产生一个变化，作为触发器。⬅️这种变化被学到了，同时这种变化被映射到了指定类别上）。而前一种encoder学到的更多的使触发器本身的共性，即触发器中像素点值的分布情况。

孰强孰弱不好说，建议都试试。

一张图+对应的触发器：
假如影子数据集有1000张图片，对于每一张图片都有一个触发器，则每张影子样本有1个触发器
对于每个参考图像都需要和1个触发器做对比

一张图+所有触发器：
假如影子数据集有1000张图片，对于每一张图片都有一个触发器，则每张影子样本有1000个触发器
对于每个参考图像都需要和1000个触发器做对比


如果在A数据集上进行微调，在B数据集上进行下游任务，则后门效果不好的话
补充新的实验，即，将A数据集拆分为2部分，在A-1进行微调，植入后门，在A-2进行下游训练，查看后门的准确率。这里由于把完整的数据集拆分了
因此可能会影响良性样本的准确率，但是不碍事，实在是太低了的话就不列出来了，因为拆分数据集后，数据量小了，准确率低是正常的

有2种情况：
1、攻击者为服务的提供方，则攻击者可以接触数据集
    预训练完整cifar10 参考样本：完整cifar10中的第0类 shadow：完整cifar10中的其他数据【需要确定这里的shadow和第0类的数量不一样，需不需要让样本数量一致？】
    则微调后门后，其他类别数据+trigger = 第0类
2、攻击者为第三方，则攻击者不能直接接触数据集
    将cifar10拆分成 A、B、C 3个部分
    先提取 C ,包含1000张（无第0类样本）
    剩下的5000张样本中，拆分成AB
    A预训练用，B作后门训练用，但是后门训练时，有参考样本（纯第0类）和shadow（无第0类）
    先需要确定需不需要让reference和shadow样本数量一致

    模型拥有者用A进行预训练，得到一个clean encoder
    敌手作为第三方使用B，假设B是从网络上搜集的照片，进行模型的微调
    其中B的第0类作为参考样本，其他类作为shadow
    shadow+trigger = 第0类
    测试时，使用C（无第0类样本）作为样本测试后门
    
总体实验如下：

预训练方法           后门攻击微调数据集     下游任务（结果的指标出在这，所以需要全部记录）
MNIST               MNIST                 MNIST
                    Fashion-MNIST         Fashion-MNIST
                    EMNIST                EMNIST
CIFAR10(✓)          CIFAR10               CIFAR10
                    GTSRB(✓)              GTSRB
                    SVHN	              SVHN
                    STL10(✓)              STL10
CIFAR100            CIFAR100              CIFAR100
                    GTSRB                 GTSRB
                    SVHN	              SVHN
                    STL10                 STL10
ImageNet(✓)         ImageNet              ImageNet
                    GTSRB                 GTSRB
                    SVHN	              SVHN
                    STL10                 STL10

随机剪枝 bottom95%+随机剪枝  top95%+随机剪枝
top95% top80% top50% top10% 越少的杂音触发器越明显，如果效果还差，则将触发器的值人为调大（但可能会影响Grad-Cam、hash、STRIP结果）
训练出来的模型在验证阶段加入噪声，以验证模型使用随机剪枝可以增强后门的鲁棒性
对比试验 Grad-Cam、hash、STRIP

攻击准确率也对比一下，虽然比不过别人
可以得出 对比学习中，由于对比学习的特性，后门隐蔽性和有效性难以并存，后续解决的问题就是有效性和隐蔽性的平衡问题！

！！！ 下游模型需要保存，用于Grad-Cam，数据可以拿去做hash和STRIP
STRIP：对比加了触发器前后的熵值
hash：直接求hash值


!!!!注意包装！为什么非要用图像隐写？可以直接扩展到 动态触发器，动态隐式触发器，差分隐私触发器，等等~把别的动态的方法都操作进去


cifar10的良性模型已经有了，然后通过微调往custom dataset加入backdoor，其中reference就是custom dataset中的需要加入后门的类

pre-train   预训练一个干净的图像编码器
backdoor    使用干净的编码器进行后门模型的微调
downstream  使用微调后的模型进行训练和测试

预训练和微调的base是同一个数据集
微调和下游的任务是同一个数据集

shadow_dataset : 正常的需要+触发器数据集
reference_dataset : 需要指定的目标类的图片

Memdata是不加trigger的shadowdata，为了暂存下来作为初始的数据，和shadowdata计算knn prediction的
memdata和shadowdata都是从args.data_dir+'train.npz'来的，只不过shadowdata加了trigger
CIFAR10Pair 返回的是同一图片的两种不同变换版本，适用于对比学习。
CIFAR10Mem 返回的是图片和其对应的标签，适用于传统的监督学习任务。

reference只有1张图，其实是无所谓的，因为，拉近的是所有shadow+trigger和reference的距离，所以所有的trigger会被认为是这一张图！
下游任务用不到reference，只有hackdoor阶段需要reference来拉近距离，将reference的模式trigger相映射，使trigger图片=reference图片

准确率无法达到像Badencoder那么高是因为，残差图像实在是太模糊了，那么我们保留top95%而非保留bottom95%呢？攻击准确率是不是会高